{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPzKxyy6am4R",
        "outputId": "a8a0800a-6633-4dc1-8071-2fd143922144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20251027_045249\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.4.0\n",
            "Python Version:     3.12.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP Thu Oct  2 10:42:05 UTC 2025\n",
            "CPU Count:          2\n",
            "Memory Avail:       11.48 GB / 12.67 GB (90.6%)\n",
            "Disk Space Avail:   61.58 GB / 107.72 GB (57.2%)\n",
            "===================================================\n",
            "Presets specified: ['medium_quality']\n",
            "Using hyperparameters preset: hyperparameters='default'\n",
            "Beginning AutoGluon training ... Time limit = 600s\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20251027_045249\"\n",
            "Train Data Rows:    600\n",
            "Train Data Columns: 26\n",
            "Label Column:       isFraud\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11753.34 MB\n",
            "\tTrain Data (Original)  Memory Usage: 0.36 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  : 14 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int', [])    :  3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t\t('object', []) :  9 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) :  9 | ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', ...]\n",
            "\t\t('float', [])    : 14 | ['TransactionAmt', 'card2', 'card3', 'card5', 'addr1', ...]\n",
            "\t\t('int', [])      :  3 | ['TransactionID', 'TransactionDT', 'card1']\n",
            "\t0.1s = Fit runtime\n",
            "\t26 features in original data used to generate 26 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 0.09 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.16s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 480, Val Rows: 120\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT ... Training model for up to 599.84s of the 599.83s of remaining time.\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/11.3 GB\n",
            "\t0.7383\t = Validation score   (roc_auc)\n",
            "\t10.15s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: LightGBM ... Training model for up to 589.67s of the 589.67s of remaining time.\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/11.2 GB\n",
            "\t0.7617\t = Validation score   (roc_auc)\n",
            "\t0.43s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: RandomForestGini ... Training model for up to 589.24s of the 589.23s of remaining time.\n",
            "\tFitting with cpus=2, gpus=0\n",
            "\t0.7122\t = Validation score   (roc_auc)\n",
            "\t0.8s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr ... Training model for up to 588.36s of the 588.36s of remaining time.\n",
            "\tFitting with cpus=2, gpus=0\n",
            "\t0.6661\t = Validation score   (roc_auc)\n",
            "\t0.6s\t = Training   runtime\n",
            "\t0.06s\t = Validation runtime\n",
            "Fitting model: CatBoost ... Training model for up to 587.69s of the 587.68s of remaining time.\n",
            "\tFitting with cpus=1, gpus=0\n",
            "\t0.6887\t = Validation score   (roc_auc)\n",
            "\t3.17s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini ... Training model for up to 584.50s of the 584.50s of remaining time.\n",
            "\tFitting with cpus=2, gpus=0\n",
            "\t0.6191\t = Validation score   (roc_auc)\n",
            "\t0.56s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr ... Training model for up to 583.86s of the 583.86s of remaining time.\n",
            "\tFitting with cpus=2, gpus=0\n",
            "\t0.5122\t = Validation score   (roc_auc)\n",
            "\t0.5s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI ... Training model for up to 583.28s of the 583.28s of remaining time.\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/11.2 GB\n",
            "\t0.4504\t = Validation score   (roc_auc)\n",
            "\t2.08s\t = Training   runtime\n",
            "\t0.02s\t = Validation runtime\n",
            "Fitting model: XGBoost ... Training model for up to 581.16s of the 581.16s of remaining time.\n",
            "\tFitting with cpus=1, gpus=0\n",
            "\t0.687\t = Validation score   (roc_auc)\n",
            "\t0.34s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch ... Training model for up to 580.81s of the 580.80s of remaining time.\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/11.1 GB\n",
            "\t0.6835\t = Validation score   (roc_auc)\n",
            "\t7.36s\t = Training   runtime\n",
            "\t0.01s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge ... Training model for up to 573.43s of the 573.42s of remaining time.\n",
            "\tFitting with cpus=1, gpus=0, mem=0.0/11.1 GB\n",
            "\t0.687\t = Validation score   (roc_auc)\n",
            "\t1.05s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 572.36s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBM': 0.538, 'XGBoost': 0.231, 'RandomForestGini': 0.077, 'CatBoost': 0.077, 'ExtraTreesGini': 0.077}\n",
            "\t0.8487\t = Validation score   (roc_auc)\n",
            "\t0.03s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 27.71s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 849.4 rows/s (120 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20251027_045249\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission_like.csv\n"
          ]
        }
      ],
      "source": [
        "# Train on synthetic IEEE-style CSVs and produce submission_like.csv\n",
        "!pip -q install -U pip setuptools wheel\n",
        "!pip -q install -U autogluon\n",
        "\n",
        "import pandas as pd\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "data_dir = \"data/ieee\"  # put the 4 CSVs here\n",
        "train_txn = pd.read_csv(f\"{data_dir}/train_transaction.csv\")\n",
        "train_id  = pd.read_csv(f\"{data_dir}/train_identity.csv\")\n",
        "test_txn  = pd.read_csv(f\"{data_dir}/test_transaction.csv\")\n",
        "test_id   = pd.read_csv(f\"{data_dir}/test_identity.csv\")\n",
        "\n",
        "train = train_txn.merge(train_id, on=\"TransactionID\", how=\"left\")\n",
        "test  = test_txn.merge(test_id,   on=\"TransactionID\", how=\"left\")\n",
        "\n",
        "label = \"isFraud\"\n",
        "predictor = TabularPredictor(label=label, problem_type=\"binary\", eval_metric=\"roc_auc\").fit(\n",
        "    train_data=train,\n",
        "    presets=\"medium_quality\",\n",
        "    time_limit=600\n",
        ")\n",
        "\n",
        "proba = predictor.predict_proba(test, as_multiclass=False)\n",
        "sub = pd.DataFrame({\"TransactionID\": test[\"TransactionID\"], \"isFraud\": proba})\n",
        "sub.to_csv(\"submission_like.csv\", index=False)\n",
        "print(\"Saved submission_like.csv\")\n"
      ]
    }
  ]
}